[2023-08-01 06:31:17,131]: HyperParameters:
[2023-08-01 06:31:17,131]: 
        Model Parameters:
        atom_embed_size         |       [192, 16, 16, 16, 16]
        edge_embed_size         |       256
        motif_embed_size        |       [256, 256]
        hidden_size             |       256
        latent_size             |       64
        depth                   |       15
        motif_depth             |       6
        virtual_node            |       False
        pooling                 |       add
        dropout                 |       0.3
        
[2023-08-01 06:31:17,131]: 
        Training Parameters:
        lr                      |       0.005
        lr_anneal_iter          |       50
        lr_anneal_rate          |       0.99
        grad_clip_norm          |       1.0
        steps                   |       30000
        beta_warmup             |       3000
        beta_min                |       0.001
        beta_max                |       0.3
        beta_anneal_period      |       40000
        prop_weight             |       0.2
        
[2023-08-01 06:31:17,327]: Begin training...
[2023-08-01 06:33:05,691]: [Step    50] | Loss. KL: 832.027, decoder_loss: 37.226, pred_loss: 0.40788 | Start_acc. top1:  0.000, top10: 0.039 | Query_acc. top1: 0.000, top10: 0.008 | Params. lr: 0.005000, beta: 0.001000.
[2023-08-01 06:33:44,484]: [Step   100] | Loss. KL: 1269.283, decoder_loss: 35.928, pred_loss: 0.47568 | Start_acc. top1:  0.004, top10: 0.031 | Query_acc. top1: 0.001, top10: 0.008 | Params. lr: 0.004950, beta: 0.001000.
[2023-08-01 06:34:23,060]: [Step   150] | Loss. KL: 90.164, decoder_loss: 35.882, pred_loss: 0.35756 | Start_acc. top1:  0.004, top10: 0.027 | Query_acc. top1: 0.000, top10: 0.015 | Params. lr: 0.004901, beta: 0.001000.
[2023-08-01 06:35:01,481]: [Step   200] | Loss. KL: 37.276, decoder_loss: 32.661, pred_loss: 0.36016 | Start_acc. top1:  0.004, top10: 0.043 | Query_acc. top1: 0.015, top10: 0.094 | Params. lr: 0.004851, beta: 0.001000.
[2023-08-01 06:35:40,203]: [Step   250] | Loss. KL: 39.375, decoder_loss: 30.531, pred_loss: 0.24382 | Start_acc. top1:  0.004, top10: 0.066 | Query_acc. top1: 0.010, top10: 0.100 | Params. lr: 0.004803, beta: 0.001000.
[2023-08-01 06:36:19,264]: [Step   300] | Loss. KL: 35.103, decoder_loss: 29.142, pred_loss: 0.26270 | Start_acc. top1:  0.008, top10: 0.066 | Query_acc. top1: 0.022, top10: 0.151 | Params. lr: 0.004755, beta: 0.001000.
