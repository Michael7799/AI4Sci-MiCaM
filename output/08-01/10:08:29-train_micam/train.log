[2023-08-01 10:08:39,044]: HyperParameters:
[2023-08-01 10:08:39,044]: 
        Model Parameters:
        atom_embed_size         |       [192, 16, 16, 16, 16]
        edge_embed_size         |       256
        motif_embed_size        |       [256, 256]
        hidden_size             |       256
        latent_size             |       64
        depth                   |       15
        motif_depth             |       6
        virtual_node            |       False
        pooling                 |       add
        dropout                 |       0.3
        
[2023-08-01 10:08:39,044]: 
        Training Parameters:
        lr                      |       0.005
        lr_anneal_iter          |       50
        lr_anneal_rate          |       0.99
        grad_clip_norm          |       1.0
        steps                   |       30000
        beta_warmup             |       3000
        beta_min                |       0.001
        beta_max                |       0.3
        beta_anneal_period      |       40000
        prop_weight             |       0.2
        
[2023-08-01 10:08:39,242]: Begin training...
[2023-08-01 10:09:14,048]: [Step    50] | Loss. KL: 1494.354, decoder_loss: 41.791, pred_loss: 0.38042 | Start_acc. top1:  0.000, top10: 0.039 | Query_acc. top1: 0.001, top10: 0.015 | Params. lr: 0.005000, beta: 0.001000.
[2023-08-01 10:09:56,836]: [Step   100] | Loss. KL: 695.255, decoder_loss: 36.205, pred_loss: 0.40302 | Start_acc. top1:  0.004, top10: 0.031 | Query_acc. top1: 0.002, top10: 0.008 | Params. lr: 0.004950, beta: 0.001000.
[2023-08-01 10:10:36,284]: [Step   150] | Loss. KL: 187.332, decoder_loss: 36.466, pred_loss: 0.35114 | Start_acc. top1:  0.008, top10: 0.039 | Query_acc. top1: 0.001, top10: 0.022 | Params. lr: 0.004901, beta: 0.001000.
[2023-08-01 10:11:14,952]: [Step   200] | Loss. KL: 36.911, decoder_loss: 33.176, pred_loss: 0.34737 | Start_acc. top1:  0.008, top10: 0.059 | Query_acc. top1: 0.019, top10: 0.125 | Params. lr: 0.004851, beta: 0.001000.
[2023-08-01 10:11:54,590]: [Step   250] | Loss. KL: 30.062, decoder_loss: 31.075, pred_loss: 0.26230 | Start_acc. top1:  0.008, top10: 0.066 | Query_acc. top1: 0.015, top10: 0.100 | Params. lr: 0.004803, beta: 0.001000.
[2023-08-01 10:12:46,842]: [Step   300] | Loss. KL: 147.071, decoder_loss: 29.553, pred_loss: 0.27212 | Start_acc. top1:  0.008, top10: 0.090 | Query_acc. top1: 0.024, top10: 0.121 | Params. lr: 0.004755, beta: 0.001000.
